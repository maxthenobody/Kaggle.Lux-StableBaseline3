{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d0c843",
   "metadata": {
    "papermill": {
     "duration": 0.005436,
     "end_time": "2024-12-26T20:00:22.706072",
     "exception": false,
     "start_time": "2024-12-26T20:00:22.700636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lux AI Season 3 @NeurIPS'24 Tutorial - Python Kit\n",
    "\n",
    "Welcome to Season 3!\n",
    "\n",
    "This notebook is the basic setup to use Jupyter Notebooks and the kaggle-environments package to develop your bot. If you plan to not use Jupyter Notebooks or any other programming language, please see our Github. The following are some important links!\n",
    "\n",
    "Competition Page: https://www.kaggle.com/competitions/lux-ai-season-3/\n",
    "\n",
    "Online Visualizer: https://s3vis.lux-ai.org/\n",
    "\n",
    "Specifications: https://github.com/Lux-AI-Challenge/Lux-Design-S3/blob/main/docs/specs.md\n",
    "\n",
    "Github: https://github.com/Lux-AI-Challenge/Lux-Design-S3\n",
    "\n",
    "Bot API: https://github.com/Lux-AI-Challenge/Lux-Design-S3/tree/main/kits\n",
    "\n",
    "And if you haven't done so already, we highly recommend you join our Discord server at https://discord.gg/aWJt3UAcgn or at the minimum follow the kaggle forums at https://www.kaggle.com/c/lux-ai-season-3/discussion. We post important announcements there such as changes to rules, events, and opportunities from our sponsors!\n",
    "\n",
    "Now let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f482a8",
   "metadata": {
    "papermill": {
     "duration": 0.004196,
     "end_time": "2024-12-26T20:00:22.715540",
     "exception": false,
     "start_time": "2024-12-26T20:00:22.711344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "We assume that you have a basic knowledge of Python and programming. It's okay if you don't know the game specifications yet! Feel free to always refer back to our [docs on Github](https://github.com/Lux-AI-Challenge/Lux-Design-S3/blob/main/docs/specs.md)\n",
    "\n",
    "## Basic Setup\n",
    "First thing to verify is that you have python 3.9 or above and have the [luxai_s3](https://pypi.org/project/luxai_s3/) package installed. Run the command below to do so. If you are using Kaggle Notebooks, **make sure to also click run-> restart and clear cell outputs** on the top right next to view and add-ons. (This fixes a bug where Kaggle Notebooks loads an incompatible package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35921214-9e6e-4a26-87f1-22db907a94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd07391-bfe8-492c-ab2d-929a0b580473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade luxai-s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6ec47-43a9-4af9-8a3a-2c836ad74e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8265fc-2d91-43e9-8a33-6f60a13cc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../Data/lux-ai-season-3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61a5e5-f2bb-4ce8-b53f-515373aea175",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88669fd-ea25-4951-9f23-e3ccd0e0e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ../Data/lux-ai-season-3/* agent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51a309",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 16.090863,
     "end_time": "2024-12-26T20:00:38.810995",
     "exception": false,
     "start_time": "2024-12-26T20:00:22.720132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, 'agent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae59ad9",
   "metadata": {
    "papermill": {
     "duration": 0.006074,
     "end_time": "2024-12-26T20:00:38.824044",
     "exception": false,
     "start_time": "2024-12-26T20:00:38.817970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then run the following command line code to verify your installation works. It will use the current starter kit agent and run one game and generate a replay file in the form of an openable HTML file. If you are using kaggle notebooks sometimes the html won't load, in which case you can download the HTML file and open it locally. The HTML viewer shown inline here can be used to upload json formatted replays by clicking the Home button or you can upload them to https://s3vis.lux-ai.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed50a4f",
   "metadata": {
    "papermill": {
     "duration": 22.177228,
     "end_time": "2024-12-26T20:01:01.007575",
     "exception": false,
     "start_time": "2024-12-26T20:00:38.830347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!luxai-s3 agent/main.py agent/main.py --output=replay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86290039",
   "metadata": {
    "papermill": {
     "duration": 0.173786,
     "end_time": "2024-12-26T20:01:01.188190",
     "exception": false,
     "start_time": "2024-12-26T20:01:01.014404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython # load the HTML replay\n",
    "IPython.display.HTML(filename='replay.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c5c85",
   "metadata": {
    "papermill": {
     "duration": 0.081828,
     "end_time": "2024-12-26T20:01:01.346690",
     "exception": false,
     "start_time": "2024-12-26T20:01:01.264862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building an Agent\n",
    "Now we know what the environment looks like, let's try building a working agent. The goal of this environment is to win a best of 5 game, where each match in the 5-match sequence is won by who has the most relic points.\n",
    "\n",
    "In our kit we provide a skeleton for building an agent. Avoid removing any function from the kit unless you know what you are doing as it may cause your agent to fail on the competition servers. This agent defintion should be stored in the `agent.py` file.\n",
    "\n",
    "The agent will have `self.player, self.opp_player, self.env_cfg` populated with the correct values at each step of an environment during competition or when you use the CLI tool to run matches. \n",
    "\n",
    "`self.env_cfg` stores the curent environment's configurations, and `self.player, self.opp_player` stores the name of your player/team and the opposition respectively (will always be \"player_0\" or \"player_1\").\n",
    "\n",
    "The Agent class below is a minimal code sample of something that takes zero actions (units do nothing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a418d0a-7b08-4290-84a7-fff68531ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8c2c7",
   "metadata": {
    "papermill": {
     "duration": 0.092931,
     "end_time": "2024-12-26T20:01:01.520683",
     "exception": false,
     "start_time": "2024-12-26T20:01:01.427752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, player: str, env_cfg) -> None:\n",
    "        self.player = player\n",
    "        self.opp_player = \"player_1\" if self.player == \"player_0\" else \"player_0\"\n",
    "        self.team_id = 0 if self.player == \"player_0\" else 1\n",
    "        self.opp_team_id = 1 if self.team_id == 0 else 0\n",
    "        np.random.seed(0)\n",
    "        self.env_cfg = env_cfg\n",
    "\n",
    "    def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        \"\"\"implement this function to decide what actions to send to each available unit. \n",
    "        \n",
    "        step is the current timestep number of the game starting from 0 going up to max_steps_in_match * match_count_per_episode - 1.\n",
    "        \"\"\"\n",
    "        unit_mask = np.array(obs[\"units_mask\"][self.team_id]) # shape (max_units, )\n",
    "        unit_positions = np.array(obs[\"units\"][\"position\"][self.team_id]) # shape (max_units, 2)\n",
    "        unit_energys = np.array(obs[\"units\"][\"energy\"][self.team_id]) # shape (max_units, 1)\n",
    "        observed_relic_node_positions = np.array(obs[\"relic_nodes\"]) # shape (max_relic_nodes, 2)\n",
    "        observed_relic_nodes_mask = np.array(obs[\"relic_nodes_mask\"]) # shape (max_relic_nodes, )\n",
    "        team_points = np.array(obs[\"team_points\"]) # points of each team, team_points[self.team_id] is the points of the your team\n",
    "        # ids of units you can control at this timestep\n",
    "        available_unit_ids = np.where(unit_mask)[0]\n",
    "        actions = np.zeros((self.env_cfg[\"max_units\"], 3), dtype=int)\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a33cb3",
   "metadata": {
    "papermill": {
     "duration": 0.080819,
     "end_time": "2024-12-26T20:01:01.682295",
     "exception": false,
     "start_time": "2024-12-26T20:01:01.601476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The next code snippet provides a simple agent evaluation function that creates an initial environment and provides an initial seed. Then it runs games and automatically saves replays to the `replays` folder as it goes. The replays are auto saved after each environment reset or when the environment is closed and can be watched by uploading them to https://s3vis.lux-ai.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88afdaed",
   "metadata": {
    "papermill": {
     "duration": 2.245903,
     "end_time": "2024-12-26T20:01:04.008828",
     "exception": false,
     "start_time": "2024-12-26T20:01:01.762925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display, Javascript\n",
    "from luxai_s3.wrappers import LuxAIS3GymEnv, RecordEpisode\n",
    "\n",
    "def render_episode(episode: RecordEpisode) -> None:\n",
    "    data = json.dumps(episode.serialize_episode_data(), separators=(\",\", \":\"))\n",
    "    display(Javascript(f\"\"\"\n",
    "var iframe = document.createElement('iframe');\n",
    "iframe.src = 'https://s3vis.lux-ai.org/#/kaggle';\n",
    "iframe.width = '100%';\n",
    "iframe.scrolling = 'no';\n",
    "\n",
    "iframe.addEventListener('load', event => {{\n",
    "    event.target.contentWindow.postMessage({data}, 'https://s3vis.lux-ai.org');\n",
    "}});\n",
    "\n",
    "new ResizeObserver(entries => {{\n",
    "    for (const entry of entries) {{\n",
    "        entry.target.height = `${{Math.round(320 + 0.3 * entry.contentRect.width)}}px`;\n",
    "    }}\n",
    "}}).observe(iframe);\n",
    "\n",
    "element.append(iframe);\n",
    "    \"\"\"))\n",
    "\n",
    "def evaluate_agents(agent_1_cls, agent_2_cls, seed=42, games_to_play=1, replay_save_dir=\"replays\"):\n",
    "    env = RecordEpisode(\n",
    "        LuxAIS3GymEnv(numpy_output=True), save_on_close=True, save_on_reset=True, save_dir=replay_save_dir\n",
    "    )\n",
    "    obs, info = env.reset(seed=seed)\n",
    "    for i in range(games_to_play):\n",
    "        obs, info = env.reset()\n",
    "        env_cfg = info[\"params\"] # only contains observable game parameters\n",
    "        player_0 = agent_1_cls(\"player_0\", env_cfg)\n",
    "        player_1 = agent_2_cls(\"player_1\", env_cfg)\n",
    "    \n",
    "        # main game loop\n",
    "        game_done = False\n",
    "        step = 0\n",
    "        print(f\"Running game {i}\")\n",
    "        while not game_done:\n",
    "            actions = dict()\n",
    "            for agent in [player_0, player_1]:\n",
    "                actions[agent.player] = agent.act(step=step, obs=obs[agent.player])\n",
    "            obs, reward, terminated, truncated, info = env.step(actions)\n",
    "            # info[\"state\"] is the environment state object, you can inspect/play around with it to e.g. print\n",
    "            # unobservable game data that agents can't see\n",
    "            dones = {k: terminated[k] | truncated[k] for k in terminated}\n",
    "            if dones[\"player_0\"] or dones[\"player_1\"]:\n",
    "                game_done = True\n",
    "            step += 1\n",
    "        render_episode(env)\n",
    "    env.close() # free up resources and save final replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6533a01",
   "metadata": {
    "papermill": {
     "duration": 23.819181,
     "end_time": "2024-12-26T20:01:27.908934",
     "exception": false,
     "start_time": "2024-12-26T20:01:04.089753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_agents(Agent, Agent) # here we evaluate our dummy agent against itself, it will auto render in the notebook\n",
    "!ls replays # see what replays we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba9417",
   "metadata": {
    "papermill": {
     "duration": 0.222261,
     "end_time": "2024-12-26T20:01:28.365049",
     "exception": false,
     "start_time": "2024-12-26T20:01:28.142788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have some agents that can be run, lets add some logic to the agent so that it can go and explore. We will use a basic strategy of sampling a random location on the game map, and having the unit move there until it reaches that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763aa17",
   "metadata": {
    "papermill": {
     "duration": 0.196392,
     "end_time": "2024-12-26T20:01:28.742058",
     "exception": false,
     "start_time": "2024-12-26T20:01:28.545666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lux.utils import direction_to\n",
    "import numpy as np\n",
    "class Agent():\n",
    "    def __init__(self, player: str, env_cfg) -> None:\n",
    "        self.player = player\n",
    "        self.opp_player = \"player_1\" if self.player == \"player_0\" else \"player_0\"\n",
    "        self.team_id = 0 if self.player == \"player_0\" else 1\n",
    "        self.opp_team_id = 1 if self.team_id == 0 else 0\n",
    "        np.random.seed(0)\n",
    "        self.env_cfg = env_cfg\n",
    "        \n",
    "        self.unit_explore_locations = dict()\n",
    "\n",
    "    def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        \"\"\"implement this function to decide what actions to send to each available unit. \n",
    "        \n",
    "        step is the current timestep number of the game starting from 0 going up to max_steps_in_match * match_count_per_episode - 1.\n",
    "        \"\"\"\n",
    "        unit_mask = np.array(obs[\"units_mask\"][self.team_id]) # shape (max_units, )\n",
    "        unit_positions = np.array(obs[\"units\"][\"position\"][self.team_id]) # shape (max_units, 2)\n",
    "        unit_energys = np.array(obs[\"units\"][\"energy\"][self.team_id]) # shape (max_units, 1)\n",
    "        observed_relic_node_positions = np.array(obs[\"relic_nodes\"]) # shape (max_relic_nodes, 2)\n",
    "        observed_relic_nodes_mask = np.array(obs[\"relic_nodes_mask\"]) # shape (max_relic_nodes, )\n",
    "        team_points = np.array(obs[\"team_points\"]) # points of each team, team_points[self.team_id] is the points of the your team\n",
    "        # ids of units you can control at this timestep\n",
    "        available_unit_ids = np.where(unit_mask)[0]\n",
    "        actions = np.zeros((self.env_cfg[\"max_units\"], 3), dtype=int)\n",
    "\n",
    "        # unit ids range from 0 to max_units - 1\n",
    "        for unit_id in available_unit_ids:\n",
    "            unit_pos = unit_positions[unit_id]\n",
    "            # every 20 steps or if a unit doesn't have an assigned location to explore\n",
    "            if step % 20 == 0 or unit_id not in self.unit_explore_locations:\n",
    "                # pick a random location on the map for the unit to explore\n",
    "                rand_loc = (np.random.randint(0, self.env_cfg[\"map_width\"]), np.random.randint(0, self.env_cfg[\"map_height\"]))\n",
    "                self.unit_explore_locations[unit_id] = rand_loc\n",
    "            # using the direction_to tool we can generate a direction that makes the unit move to the saved location\n",
    "            # note that the first index of each unit's action represents the type of action. See specs for more details\n",
    "            actions[unit_id] = [direction_to(unit_pos, self.unit_explore_locations[unit_id]), 0, 0]\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804dfe4b",
   "metadata": {
    "papermill": {
     "duration": 22.391019,
     "end_time": "2024-12-26T20:01:51.314519",
     "exception": false,
     "start_time": "2024-12-26T20:01:28.923500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_agents(Agent, Agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f500419",
   "metadata": {
    "papermill": {
     "duration": 0.343024,
     "end_time": "2024-12-26T20:01:52.014319",
     "exception": false,
     "start_time": "2024-12-26T20:01:51.671295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Great now that we have randomly moving units, we now want to move to locations that give our team points, namely relic nodes. Recall that in this season's game, you can only see what your units see, so information about the dynamically changing map is crucical. For starters we will write some code to track every relic node location we find as we need to go there to get points. Because each game has 5 matches and the map is preserved in between matches, we can save map information between matches to improve our agent's gameplay. In the example code below, we implement a very basic strategy to leverage this information by simply making all units move towards a relic node. Since to gain points a unit must move on top of a hidden tile near the relic node (in a 5x5 square centered at the node) we add code to make units move randomly around relic nodes if they are close enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da71c4",
   "metadata": {
    "papermill": {
     "duration": 0.357413,
     "end_time": "2024-12-26T20:01:52.715542",
     "exception": false,
     "start_time": "2024-12-26T20:01:52.358129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lux.utils import direction_to\n",
    "import numpy as np\n",
    "class Agent():\n",
    "    def __init__(self, player: str, env_cfg) -> None:\n",
    "        self.player = player\n",
    "        self.opp_player = \"player_1\" if self.player == \"player_0\" else \"player_0\"\n",
    "        self.team_id = 0 if self.player == \"player_0\" else 1\n",
    "        self.opp_team_id = 1 if self.team_id == 0 else 0\n",
    "        np.random.seed(0)\n",
    "        self.env_cfg = env_cfg\n",
    "        \n",
    "        self.unit_explore_locations = dict()\n",
    "        self.relic_node_positions = []\n",
    "        self.discovered_relic_nodes_ids = set()\n",
    "\n",
    "    def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        \"\"\"implement this function to decide what actions to send to each available unit. \n",
    "        \n",
    "        step is the current timestep number of the game starting from 0 going up to max_steps_in_match * match_count_per_episode - 1.\n",
    "        \"\"\"\n",
    "        unit_mask = np.array(obs[\"units_mask\"][self.team_id]) # shape (max_units, )\n",
    "        unit_positions = np.array(obs[\"units\"][\"position\"][self.team_id]) # shape (max_units, 2)\n",
    "        unit_energys = np.array(obs[\"units\"][\"energy\"][self.team_id]) # shape (max_units, 1)\n",
    "        observed_relic_node_positions = np.array(obs[\"relic_nodes\"]) # shape (max_relic_nodes, 2)\n",
    "        observed_relic_nodes_mask = np.array(obs[\"relic_nodes_mask\"]) # shape (max_relic_nodes, )\n",
    "        team_points = np.array(obs[\"team_points\"]) # points of each team, team_points[self.team_id] is the points of the your team\n",
    "        # ids of units you can control at this timestep\n",
    "        available_unit_ids = np.where(unit_mask)[0]\n",
    "        actions = np.zeros((self.env_cfg[\"max_units\"], 3), dtype=int)\n",
    "\n",
    "\n",
    "        # visible relic nodes\n",
    "        visible_relic_node_ids = set(np.where(observed_relic_nodes_mask)[0])\n",
    "        # save any new relic nodes that we discover for the rest of the game.\n",
    "        for id in visible_relic_node_ids:\n",
    "            if id not in self.discovered_relic_nodes_ids:\n",
    "                self.discovered_relic_nodes_ids.add(id)\n",
    "                self.relic_node_positions.append(observed_relic_node_positions[id])\n",
    "\n",
    "        # unit ids range from 0 to max_units - 1\n",
    "        for unit_id in available_unit_ids:\n",
    "            unit_pos = unit_positions[unit_id]\n",
    "            # if we found at least one relic node\n",
    "            if len(self.relic_node_positions) > 0:\n",
    "                nearest_relic_node_position = self.relic_node_positions[0]\n",
    "                manhattan_distance = abs(unit_pos[0] - nearest_relic_node_position[0]) + abs(unit_pos[1] - nearest_relic_node_position[1])\n",
    "                \n",
    "                # if close to the relic node we want to move randomly around it and hope to gain points\n",
    "                if manhattan_distance <= 4:\n",
    "                    random_direction = np.random.randint(0, 5)\n",
    "                    actions[unit_id] = [random_direction, 0, 0]\n",
    "                else:\n",
    "                    # otherwise we want to move towards the relic node\n",
    "                    actions[unit_id] = [direction_to(unit_pos, nearest_relic_node_position), 0, 0]\n",
    "            # every 20 steps or if a unit doesn't have an assigned location to explore\n",
    "            else:\n",
    "                if step % 20 == 0 or unit_id not in self.unit_explore_locations:\n",
    "                    # pick a random location on the map for the unit to explore\n",
    "                    rand_loc = (np.random.randint(0, self.env_cfg[\"map_width\"]), np.random.randint(0, self.env_cfg[\"map_height\"]))\n",
    "                    self.unit_explore_locations[unit_id] = rand_loc\n",
    "                # using the direction_to tool we can generate a direction that makes the unit move to the saved location\n",
    "                # note that the first index of each unit's action represents the type of action. See specs for more details\n",
    "                actions[unit_id] = [direction_to(unit_pos, self.unit_explore_locations[unit_id]), 0, 0]\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b5d65",
   "metadata": {
    "papermill": {
     "duration": 22.525078,
     "end_time": "2024-12-26T20:02:15.582371",
     "exception": false,
     "start_time": "2024-12-26T20:01:53.057293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_agents(Agent, Agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b39d7f",
   "metadata": {
    "papermill": {
     "duration": 0.526286,
     "end_time": "2024-12-26T20:02:16.613501",
     "exception": false,
     "start_time": "2024-12-26T20:02:16.087215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create a submission\n",
    "Now we need to create a .tar.gz file with main.py (and agent.py) at the top level. We can then upload this. In the notebook you can write to a local file with the %%writefile command, just copy your agent code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd991b",
   "metadata": {
    "papermill": {
     "duration": 0.540241,
     "end_time": "2024-12-26T20:02:17.678235",
     "exception": false,
     "start_time": "2024-12-26T20:02:17.137994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile agent/agent.py\n",
    "from lux.utils import direction_to\n",
    "import numpy as np\n",
    "class Agent():\n",
    "    def __init__(self, player: str, env_cfg) -> None:\n",
    "        self.player = player\n",
    "        self.opp_player = \"player_1\" if self.player == \"player_0\" else \"player_0\"\n",
    "        self.team_id = 0 if self.player == \"player_0\" else 1\n",
    "        self.opp_team_id = 1 if self.team_id == 0 else 0\n",
    "        np.random.seed(0)\n",
    "        self.env_cfg = env_cfg\n",
    "        \n",
    "        self.unit_explore_locations = dict()\n",
    "        self.relic_node_positions = []\n",
    "        self.discovered_relic_nodes_ids = set()\n",
    "\n",
    "    def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        \"\"\"implement this function to decide what actions to send to each available unit. \n",
    "        \n",
    "        step is the current timestep number of the game starting from 0 going up to max_steps_in_match * match_count_per_episode - 1.\n",
    "        \"\"\"\n",
    "        unit_mask = np.array(obs[\"units_mask\"][self.team_id]) # shape (max_units, )\n",
    "        unit_positions = np.array(obs[\"units\"][\"position\"][self.team_id]) # shape (max_units, 2)\n",
    "        unit_energys = np.array(obs[\"units\"][\"energy\"][self.team_id]) # shape (max_units, 1)\n",
    "        observed_relic_node_positions = np.array(obs[\"relic_nodes\"]) # shape (max_relic_nodes, 2)\n",
    "        observed_relic_nodes_mask = np.array(obs[\"relic_nodes_mask\"]) # shape (max_relic_nodes, )\n",
    "        team_points = np.array(obs[\"team_points\"]) # points of each team, team_points[self.team_id] is the points of the your team\n",
    "        # ids of units you can control at this timestep\n",
    "        available_unit_ids = np.where(unit_mask)[0]\n",
    "        actions = np.zeros((self.env_cfg[\"max_units\"], 3), dtype=int)\n",
    "\n",
    "\n",
    "        # visible relic nodes\n",
    "        visible_relic_node_ids = set(np.where(observed_relic_nodes_mask)[0])\n",
    "        # save any new relic nodes that we discover for the rest of the game.\n",
    "        for id in visible_relic_node_ids:\n",
    "            if id not in self.discovered_relic_nodes_ids:\n",
    "                self.discovered_relic_nodes_ids.add(id)\n",
    "                self.relic_node_positions.append(observed_relic_node_positions[id])\n",
    "\n",
    "        # unit ids range from 0 to max_units - 1\n",
    "        for unit_id in available_unit_ids:\n",
    "            unit_pos = unit_positions[unit_id]\n",
    "            # if we found at least one relic node\n",
    "            if len(self.relic_node_positions) > 0:\n",
    "                nearest_relic_node_position = self.relic_node_positions[0]\n",
    "                manhattan_distance = abs(unit_pos[0] - nearest_relic_node_position[0]) + abs(unit_pos[1] - nearest_relic_node_position[1])\n",
    "                \n",
    "                # if close to the relic node we want to move randomly around it and hope to gain points\n",
    "                if manhattan_distance <= 4:\n",
    "                    random_direction = np.random.randint(0, 5)\n",
    "                    actions[unit_id] = [random_direction, 0, 0]\n",
    "                else:\n",
    "                    # otherwise we want to move towards the relic node\n",
    "                    actions[unit_id] = [direction_to(unit_pos, nearest_relic_node_position), 0, 0]\n",
    "            # every 20 steps or if a unit doesn't have an assigned location to explore\n",
    "            else:\n",
    "                if step % 20 == 0 or unit_id not in self.unit_explore_locations:\n",
    "                    # pick a random location on the map for the unit to explore\n",
    "                    rand_loc = (np.random.randint(0, self.env_cfg[\"map_width\"]), np.random.randint(0, self.env_cfg[\"map_height\"]))\n",
    "                    self.unit_explore_locations[unit_id] = rand_loc\n",
    "                # using the direction_to tool we can generate a direction that makes the unit move to the saved location\n",
    "                # note that the first index of each unit's action represents the type of action. See specs for more details\n",
    "                actions[unit_id] = [direction_to(unit_pos, self.unit_explore_locations[unit_id]), 0, 0]\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d84fa",
   "metadata": {
    "papermill": {
     "duration": 0.8278,
     "end_time": "2024-12-26T20:02:19.033739",
     "exception": false,
     "start_time": "2024-12-26T20:02:18.205939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd agent && tar -czf submission.tar.gz *\n",
    "!mv agent/submission.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf03f3",
   "metadata": {
    "papermill": {
     "duration": 0.597673,
     "end_time": "2024-12-26T20:02:20.175097",
     "exception": false,
     "start_time": "2024-12-26T20:02:19.577424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submit\n",
    "Now open the /kaggle/working folder and find submission.tar.gz, download that file, navigate to the \"MySubmissions\" tab in https://www.kaggle.com/competitions/lux-ai-season-3/submissions and upload your submission! It should play a validation match against itself and once it succeeds it will be automatically matched against other players' submissions. Newer submissions will be prioritized for games over older ones. Your team is limited in the number of successful submissions per day so we highly recommend testing your bot locally before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac912e3",
   "metadata": {
    "papermill": {
     "duration": 0.549973,
     "end_time": "2024-12-26T20:02:21.335746",
     "exception": false,
     "start_time": "2024-12-26T20:02:20.785773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CLI Tool\n",
    "\n",
    "To test your agent without using the python API you can also run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105e0ab",
   "metadata": {
    "papermill": {
     "duration": 18.68863,
     "end_time": "2024-12-26T20:02:40.551737",
     "exception": false,
     "start_time": "2024-12-26T20:02:21.863107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!luxai-s3 agent/main.py agent/main.py --seed 101 -o replay.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3041b67",
   "metadata": {
    "papermill": {
     "duration": 0.534292,
     "end_time": "2024-12-26T20:02:41.624793",
     "exception": false,
     "start_time": "2024-12-26T20:02:41.090501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "which uses a seed of 101 and generates a replay.html file that you can click and watch. Optionally if you specify `-o replay.json` you can upload replay.json to http://s3vis.lux-ai.org/. We **highly recommend** watching on a separate window instead of watching here on a notebook as the notebook screen width is quite small.\n",
    "\n",
    "The CLI tool enables you to easily run episodes between any two agents (python or not) and provides a flexible tournament running tool to evaluate many agents together. Documentation on this tool can be found here: https://github.com/Lux-AI-Challenge/Lux-Design-S3/tree/main/luxai_runner/README.md"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10395677,
     "sourceId": 86411,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 143.048125,
   "end_time": "2024-12-26T20:02:43.573801",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-26T20:00:20.525676",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
